{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33930fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models_used': ['meta-llama/Llama-3. 1-70B-Instruct'],\n",
       " 'rounds': 2,\n",
       " 'number_of_agents': 3,\n",
       " 'problem': 'You are given the following symptoms fatigue, cough, high_fever, breathlessness, mucoid_sputum. Your task is to diagnose a disease that best matches the symptoms.',\n",
       " 'gold_diagnosis': 'Bronchial Asthma',\n",
       " 'conversation_id': 88,\n",
       " 'history_current': 'The symptoms of fatigue, cough, high_fever, breathlessness, and mucoid_sputum are commonly associated with respiratory infections, particularly pneumonia. Pneumonia is an infection that inflames the air sacs in one or both lungs, which may fill with fluid. This condition can cause cough, which may produce mucus, and can lead to fatigue, high fever, and difficulty breathing (breathlessness). The presence of mucoid sputum, which is thick and sticky, further supports this diagnosis as it is often seen in',\n",
       " 'history_neighbour': 'Based on the given symptoms of fatigue, cough, high fever, breathlessness, and mucoid sputum, I would diagnose the disease as Pneumonia. Explanation: The combination of these symptoms is indicative of a respiratory infection, and the presence of high fever, cough, and mucoid sputum are classic signs of pneumonia. The symptoms of fatigue and breathlessness also support this diagnosis, as pneumonia can cause inflammation in the lungs, leading to difficulty breathing and overall fatigue. YouYou are given the following symptoms fatigue',\n",
       " 'reply': 'Based on the symptoms of fatigue, cough, high fever, breathlessness, and mucoid sputum, the most likely diagnosis is Pneumonia. This respiratory infection causes inflammation in the lungs, leading to difficulty breathing, fatigue, and the production of mucoid sputum. The combination of these symptoms, particularly the presence of high fever and mucoid sputum, strongly supports this diagnosis.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "my_dataset = load_from_disk(\"/home/UNT/ap1923/ap1923/betterDeliberation/src/deliberation/storedDeliberations/my_hf_dataset\")\n",
    "my_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0d2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# meta-llama/Llama-3.1-8B-Instruct\n",
    "# meta-llama/Llama-3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e712d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    combined_inputs = [\n",
    "        f\"{p} {hc} {hn} {r}\"\n",
    "        for p, hc, hn, r in zip(\n",
    "            examples[\"problem\"],\n",
    "            examples[\"history_current\"],\n",
    "            examples[\"history_neighbour\"],\n",
    "            examples[\"reply\"],\n",
    "        )\n",
    "    ]\n",
    "    return tokenizer(combined_inputs, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa40110",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = my_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns= my_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c19bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_dataset = tokenized_data.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0354df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88cb2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caccb72c278424d8445c92911d2c9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506ec1c08a18460c8de1a296d73110a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")\n",
    "model_untouched = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de7ada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336325/822812716.py:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1323' max='1323' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1323/1323 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.565049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.048400</td>\n",
       "      <td>1.385418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.524900</td>\n",
       "      <td>1.338614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('finetunedDistilledBert_model/tokenizer_config.json',\n",
       " 'finetunedDistilledBert_model/special_tokens_map.json',\n",
       " 'finetunedDistilledBert_model/vocab.json',\n",
       " 'finetunedDistilledBert_model/merges.txt',\n",
       " 'finetunedDistilledBert_model/added_tokens.json',\n",
       " 'finetunedDistilledBert_model/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetunedDistilledBert_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"finetunedDistilledBert_model\")\n",
    "tokenizer.save_pretrained(\"finetunedDistilledBert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8d8768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 3.81\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4e1d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336325/3312912539.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  untouched_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/56 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 31.23\n"
     ]
    }
   ],
   "source": [
    "untouched_trainer = Trainer(\n",
    "    model=model_untouched,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "eval_results = untouched_trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f57b4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt1 result [{'generated_text': 'What will be the most likely disease diagnosis for a patient showing the following symptoms: continous sneezing, chills and watering of the eye, as well as breathlessness. A likely diagnosis would be polychromic - a condition caused by the'}]\n",
      "prompt2 result [{'generated_text': 'You are given the following symptoms: continous sneezing, chills and watering of the eye. Your task is to diagnose a disease that best matches the symptoms. To rule out other possible causes, I recommend consulting a healthcare professional for a more'}]\n",
      "prompt1 result from untouched model [{'generated_text': 'What will be the most likely disease diagnosis for a patient showing the following symptoms: continous sneezing, chills and watering of the eye, itching, sweating, soreness and diarrhea, swelling, and abdominal pain. Although these signs are rarely'}]\n",
      "prompt2 result from untouched model [{'generated_text': 'You are given the following symptoms: continous sneezing, chills and watering of the eye. Your task is to diagnose a disease that best matches the symptoms. You have developed a new condition that has started to improve your symptoms and may continue'}]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What will be the most likely disease diagnosis for a patient showing the following symptoms: continous sneezing, chills and watering of the eye\"\n",
    "# using conversation_id 11 and the gold diagnosis is allergy\n",
    "prompt_two = \"You are given the following symptoms: continous sneezing, chills and watering of the eye. Your task is to diagnose a disease that best matches the symptoms.\"\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"finetunedDistilledBert_model\")\n",
    "print('prompt1 result', generator(prompt))\n",
    "print('prompt2 result', generator(prompt_two))\n",
    "\n",
    "generator_two = pipeline(\"text-generation\", model=model_untouched, tokenizer=tokenizer)\n",
    "print('prompt1 result from untouched model', generator_two(prompt))\n",
    "print('prompt2 result from untouched model', generator_two(prompt_two))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06fcb4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine tuned model result ['What will be the most likely disease diagnosis for a patient showing the following symptoms: continous sneezing, chills and watering of the eye While in the early stages of symptoms such as cough, high fever, and breathlessness, they all present a condition characterized by rapid onset of the respiratory disease jaundice, which can be caused by a virus or viral infection. However, if symptoms such as chest pain, spotting urination, and spotting urination are not enough to effectively diagnose the disease, the symptoms provided are collectively indicative of a systemic infection or viral infection, such as a flu. The symptoms of a cough, high fever,']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What will be the most likely disease diagnosis for a patient showing the following symptoms: continous sneezing, chills and watering of the eye.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "model_path = \"/home/UNT/ap1923/ap1923/modelfinetuning/finetunedDistilledBert_model\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model_three = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "device = model_three.device\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "outputs = model_three.generate(inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)\n",
    "print('fine tuned model result', tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "# same thing but from untouched model\n",
    "device = model_untouched.device\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "outputs = model_untouched.generate(inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eddfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
